{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Welcome to you first hands-on on word embeddings!!!\n",
    "\n",
    "- In this hands-on you will be using pretrained word vectors from stanford nlp which you can find [here](https://nlp.stanford.edu/projects/glove/)\n",
    "- Follow the instruction provided for cell to write the code in each cell.\n",
    "- Before submit your notebook. Restart the kernel and run all the cell. Make sure that any cell shouldn't cause any error or problem.\n",
    "- Don't forget to run the last cell in the jupyter notebook, failing which your efforts will be invalid.\n",
    "- Don't delete any cell given in the notebook.\n",
    "\n",
    "#### Each word vectors is of dimension 50\n",
    "#### You will be performing following operations:\n",
    "    - Load the pretrained vectors from the text file\n",
    "    - Write a function to find cosine similarity between two word vectors\n",
    "    - Write an function to find analogy analogy problems such as King : Queen :: Men : __?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task1\n",
    "- A text file having the trained word vectors is provided for you as word2vec.txt in the same working directory.\n",
    "- Each line in the file is space seperated values where first value is the word and the remaing values are its vector representation.\n",
    "\n",
    "### Define a function get_word_vectors()\n",
    "    parameters: file_name  \n",
    "    returns: word_to_vec: dictionary with key as the word and the value is the corresponding word vectors as 1-d array each element of type float32.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def get_word_vectors(file_name):\n",
    "    ###Start code here\n",
    "    word_to_vec = {}\n",
    "    with open(file_name, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.strip().split()\n",
    "            word = values[0]\n",
    "            vector = np.array(values[1:], dtype=np.float32)\n",
    "            word_to_vec[word] = vector\n",
    "    \n",
    "    \n",
    "    \n",
    "    ###End code\n",
    "    return word_to_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the function you defined above read the word vectors from the file word_vectors.txt and assign it to variable word_to_vec\n",
    "\n",
    "### Expected output  (showing only first few values of vectors)\n",
    "   Father:  [ 0.095496   0.70418   -0.40777   -0.80844    1.256      0.77071 ...]  \n",
    "   mother:  [ 0.4336     1.0727    -0.6196    -0.80679    1.2519     1.3767 ....]  \n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Father:  [ 0.095496   0.70418   -0.40777   -0.80844    1.256      0.77071\n",
      " -1.0695     0.76847   -0.87813   -0.0080954  0.43884    1.0476\n",
      " -0.45071   -0.58931    0.83246   -0.038442  -0.73533    0.26389\n",
      "  0.12617    0.57623   -0.23866    1.0922    -0.3367     0.081537\n",
      "  0.84798   -2.4795    -0.40351   -0.84087    0.12034    0.29074\n",
      "  1.9711    -0.50886   -0.45977   -0.13617    0.55613    0.22924\n",
      " -0.18947    0.43544    0.65151    0.043537  -0.1162     0.72196\n",
      " -0.66163   -0.17272    0.27367   -0.28169   -0.82025   -1.5089\n",
      "  0.052787  -0.035579 ]\n",
      "mother:  [ 0.4336     1.0727    -0.6196    -0.80679    1.2519     1.3767\n",
      " -0.93533    0.76088   -0.0056654 -0.063649   0.30297    0.52401\n",
      "  0.2843    -0.38162    0.98797    0.093184  -1.1464     0.070523\n",
      "  0.58012    0.50644   -0.24026    1.7344     0.020735   0.43704\n",
      "  1.2148    -2.2483    -0.41168   -0.24922    0.31225   -0.49464\n",
      "  2.0441    -0.012111  -0.19556    0.085665   0.27682    0.015702\n",
      "  0.0067683  0.12759    0.87008   -0.40641   -0.21057    0.41651\n",
      " -0.021812  -0.53649    0.54095   -0.43442   -0.52489   -2.0277\n",
      "  0.13136    0.11704  ]\n"
     ]
    }
   ],
   "source": [
    "word_to_vec = get_word_vectors('word2vec.txt')\n",
    "father = word_to_vec[\"father\"]\n",
    "mother = word_to_vec[\"mother\"]\n",
    "print(\"Father: \", father)\n",
    "print(\"mother: \", mother)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Task 2 Determine the cosine similarity between two word vectors\n",
    "- The formula for cosine similarity is given by\n",
    "  score = $\\large \\frac{U.V}{\\sqrt{||U||.||V||}}$ where ||U|| and ||V|| is the sum of the squares of the elemnts individual vectors\n",
    "  \n",
    "\n",
    "### Define a function named cosine_similarity()\n",
    "    - parameters u, v are the word vectors whose similarity has to be determined\n",
    "    - returns - score: cosine similarity of u and v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(u, v):\n",
    "    ###Start code here\n",
    "    dot_product = np.dot(u, v)\n",
    "    norm_u = np.linalg.norm(u)\n",
    "    norm_v = np.linalg.norm(v)\n",
    "    score = dot_product / (norm_u * norm_v)\n",
    "    \n",
    "    \n",
    "    ###End code\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the bellow cell to find the similarity between word vectors paris and rome\n",
    "### Expected output\n",
    "   similarity score : 0.7099411"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity score : 0.7099411\n"
     ]
    }
   ],
   "source": [
    "paris = word_to_vec[\"paris\"]\n",
    "rome = word_to_vec[\"rome\"]\n",
    "print(\"similarity score :\", cosine_similarity(paris, rome))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3\n",
    "In the word analogy task, we complete the analogy . In detail, we are trying to find a word d, such that the associated word vectors $u_1, v_1, u_2, v_2$ are related in the following manner: $u_1 - v_1 \\approx u_2 - v_2$. We will measure the similarity between $u_1 - v_1$ and $u_2 - v_2$ using cosine similarity.\n",
    "#### As an example,  to find the best possible word for the analogy King : Queen :: Men : __?_ you will perform following steps:\n",
    "- extract word vectors of three words king, queen and men\n",
    "- find the element wise difference between the two word vectors king and queen as V1\n",
    "- Find the element wise difference between the word vector men and each word vector in word_to_vec ditionary as V2 (while doing so exclude the words of interest ie. king, queen and men)\n",
    "- Find the cosine similarity between vector V1 and V2 and choose the word from the word_to_vec ditionary that has maximum similarity between V1 and V2.\n",
    "### Define the function named find_analogy()\n",
    "    - parameters: word1 - string corresponding to word vector $u_1$, word2 - string corresponding to word vector $v_1$, word3 - string corresponding to word vector $u_2$, word_to_vec - dictionary of words and their corresponding vectors\n",
    "    - returns: best_word -  the word such that $u_1$ - $v_1$ is close to $v\\_best\\_word$ - $v_c$, as measured by cosine similarity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_analogy(word_1, word_2, word_3, word_to_vec):\n",
    "    \"\"\"Finds the best word to complete the analogy: word1 -> word2 :: word3 -> ?\"\"\"\n",
    "    if word_1 not in word_to_vec or word_2 not in word_to_vec or word_3 not in word_to_vec:\n",
    "        return None\n",
    "\n",
    "    # Compute analogy vector (do NOT normalize this)\n",
    "    v_expected = word_to_vec[word_2] - word_to_vec[word_1] + word_to_vec[word_3]\n",
    "\n",
    "    similarity_scores = []\n",
    "    \n",
    "    for word, vec in word_to_vec.items():\n",
    "        if word in {word_1, word_2, word_3}:\n",
    "            continue  # Skip input words\n",
    "\n",
    "        # Normalize individual word vector before computing similarity\n",
    "        vec = vec / np.linalg.norm(vec)\n",
    "\n",
    "        # Compute cosine similarity\n",
    "        similarity = cosine_similarity(v_expected, vec)\n",
    "\n",
    "        similarity_scores.append((word, similarity))\n",
    "\n",
    "    # Sort results by highest similarity\n",
    "    similarity_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return similarity_scores[0][0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the below  code to check your above defined function\n",
    "\n",
    "#### Expected output:\n",
    "    father -> son :: mother -> daughter\n",
    "    india -> delhi :: japan -> tokyo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "father -> son :: mother -> daughter\n",
      "india -> delhi :: japan -> tokyo\n"
     ]
    }
   ],
   "source": [
    "print ('{} -> {} :: {} -> {}'.format('father', 'son', 'mother',find_analogy('father', 'son', 'mother', word_to_vec)))\n",
    "print ('{} -> {} :: {} -> {}'.format('india', 'delhi', 'japan',find_analogy('india', 'delhi', 'japan', word_to_vec)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the below cells to save your answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from test_nlpusingdp_word2vec import word2vec as w2v\n",
    "w2v.save_ans1(find_analogy, word_to_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
